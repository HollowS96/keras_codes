{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Exercise \n",
    "\n",
    "California Housing Data\n",
    "\n",
    "This data set contains information about all the block groups in California from the 1990 Census. In this sample a block group on average includes 1425.5 individuals living in a geographically compact area. \n",
    "\n",
    "The task is to aproximate the median house value of each block from the values of the rest of the variables. \n",
    "\n",
    " It has been obtained from the LIACC repository. The original page where the data set can be found is: http://www.liaad.up.pt/~ltorgo/Regression/DataSets.html.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Features:\n",
    " \n",
    "* housingMedianAge: continuous. \n",
    "* totalRooms: continuous. \n",
    "* totalBedrooms: continuous. \n",
    "* population: continuous. \n",
    "* households: continuous. \n",
    "* medianIncome: continuous. \n",
    "* medianHouseValue: continuous. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import the cal_housing_clean.csv file with pandas. Separate it into a training (70%) and testing set(30%).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cal_housing_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "0              41.0       880.0          129.0       322.0       126.0   \n",
       "1              21.0      7099.0         1106.0      2401.0      1138.0   \n",
       "2              52.0      1467.0          190.0       496.0       177.0   \n",
       "3              52.0      1274.0          235.0       558.0       219.0   \n",
       "4              52.0      1627.0          280.0       565.0       259.0   \n",
       "\n",
       "   medianIncome  medianHouseValue  \n",
       "0        8.3252          452600.0  \n",
       "1        8.3014          358500.0  \n",
       "2        7.2574          352100.0  \n",
       "3        5.6431          341300.0  \n",
       "4        3.8462          342200.0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.639486</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>537.898014</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>206855.816909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.585558</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>421.247906</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>115395.615874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1447.750000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.563400</td>\n",
       "      <td>119600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.534800</td>\n",
       "      <td>179700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>4.743250</td>\n",
       "      <td>264725.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       housingMedianAge    totalRooms  totalBedrooms    population  \\\n",
       "count      20640.000000  20640.000000   20640.000000  20640.000000   \n",
       "mean          28.639486   2635.763081     537.898014   1425.476744   \n",
       "std           12.585558   2181.615252     421.247906   1132.462122   \n",
       "min            1.000000      2.000000       1.000000      3.000000   \n",
       "25%           18.000000   1447.750000     295.000000    787.000000   \n",
       "50%           29.000000   2127.000000     435.000000   1166.000000   \n",
       "75%           37.000000   3148.000000     647.000000   1725.000000   \n",
       "max           52.000000  39320.000000    6445.000000  35682.000000   \n",
       "\n",
       "         households  medianIncome  medianHouseValue  \n",
       "count  20640.000000  20640.000000      20640.000000  \n",
       "mean     499.539680      3.870671     206855.816909  \n",
       "std      382.329753      1.899822     115395.615874  \n",
       "min        1.000000      0.499900      14999.000000  \n",
       "25%      280.000000      2.563400     119600.000000  \n",
       "50%      409.000000      3.534800     179700.000000  \n",
       "75%      605.000000      4.743250     264725.000000  \n",
       "max     6082.000000     15.000100     500001.000000  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['medianHouseValue']\n",
    "data = data.drop(columns=['medianHouseValue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(data,labels,test_size=0.2,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Feature Data\n",
    "\n",
    "** Use sklearn preprocessing to create a MinMaxScaler for the feature data. Fit this scaler only to the training data. Then use it to transform X_test and X_train. Then use the scaled X_test and X_train along with pd.Dataframe to re-create two dataframes of scaled data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(data = scaler.transform(X_train) ,columns=X_train.columns,index=X_train.index)\n",
    "X_test  = pd.DataFrame(scaler.transform(X_test)  ,columns=X_test.columns,index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
      "0              0.784314    0.022331       0.019863    0.008941    0.020556   \n",
      "1              0.392157    0.180503       0.171477    0.067210    0.186976   \n",
      "2              1.000000    0.037260       0.029330    0.013818    0.028943   \n",
      "3              1.000000    0.032352       0.036313    0.015555    0.035849   \n",
      "4              1.000000    0.041330       0.043296    0.015752    0.042427   \n",
      "5              1.000000    0.023323       0.032899    0.011491    0.031574   \n",
      "6              1.000000    0.064423       0.075729    0.030578    0.084361   \n",
      "7              1.000000    0.078895       0.106456    0.032344    0.106233   \n",
      "8              0.803922    0.064932       0.103042    0.033717    0.097681   \n",
      "9              1.000000    0.090213       0.109559    0.043387    0.117250   \n",
      "10             1.000000    0.055954       0.067194    0.025421    0.065943   \n",
      "11             1.000000    0.089043       0.116543    0.042070    0.120539   \n",
      "12             1.000000    0.063304       0.073402    0.030690    0.076797   \n",
      "13             1.000000    0.017651       0.029485    0.009585    0.028449   \n",
      "14             1.000000    0.067170       0.096989    0.033885    0.101792   \n",
      "15             0.960784    0.028435       0.043762    0.019451    0.043249   \n",
      "16             1.000000    0.049952       0.053693    0.022142    0.054267   \n",
      "17             1.000000    0.031182       0.045313    0.018078    0.049663   \n",
      "18             0.960784    0.056895       0.070453    0.027663    0.068739   \n",
      "19             1.000000    0.038176       0.046089    0.019255    0.045058   \n",
      "20             0.764706    0.019050       0.028399    0.011379    0.027134   \n",
      "21             0.803922    0.041635       0.056797    0.025954    0.060023   \n",
      "22             1.000000    0.061905       0.083799    0.028364    0.078441   \n",
      "23             1.000000    0.042881       0.052142    0.023824    0.053281   \n",
      "24             1.000000    0.056514       0.067660    0.028112    0.069232   \n",
      "25             0.784314    0.013556       0.018932    0.008801    0.019405   \n",
      "26             0.941176    0.028689       0.037709    0.016929    0.039138   \n",
      "27             1.000000    0.048222       0.065177    0.030802    0.065121   \n",
      "28             0.960784    0.052902       0.076195    0.031615    0.077619   \n",
      "29             1.000000    0.018490       0.024674    0.010987    0.025325   \n",
      "...                 ...         ...            ...         ...         ...   \n",
      "16482          0.588235    0.049621       0.056642    0.027916    0.051801   \n",
      "16483          0.254902    0.065848       0.076971    0.038342    0.078605   \n",
      "16484          0.235294    0.016506       0.015673    0.008352    0.016938   \n",
      "16485          0.333333    0.106160       0.108473    0.060568    0.114784   \n",
      "16486          0.352941    0.084541       0.086903    0.043191    0.083868   \n",
      "16487          0.431373    0.019330       0.021570    0.009950    0.023023   \n",
      "16488          0.509804    0.060990       0.067349    0.030326    0.072850   \n",
      "16489          0.392157    0.059286       0.058349    0.029990    0.054432   \n",
      "16490          0.509804    0.042754       0.044538    0.024384    0.042263   \n",
      "16491          0.313725    0.062872       0.074333    0.046134    0.074330   \n",
      "16492          0.607843    0.027494       0.029019    0.013117    0.029107   \n",
      "16493          0.392157    0.052444       0.052917    0.028532    0.058872   \n",
      "16494          0.686275    0.017320       0.024519    0.014070    0.023023   \n",
      "16495          0.607843    0.065161       0.079454    0.033493    0.075317   \n",
      "16496          0.235294    0.102447       0.115301    0.062922    0.125802   \n",
      "16497          0.372549    0.062465       0.076040    0.034306    0.078934   \n",
      "16498          0.529412    0.060176       0.066574    0.034418    0.066108   \n",
      "16499          0.607843    0.057480       0.064401    0.032316    0.066272   \n",
      "16500          0.607843    0.074114       0.081782    0.041005    0.077619   \n",
      "16501          0.450980    0.043517       0.050745    0.035175    0.053116   \n",
      "16502          0.588235    0.017168       0.022191    0.014574    0.025983   \n",
      "16503          0.529412    0.010351       0.015984    0.006755    0.015951   \n",
      "16504          0.666667    0.028104       0.035071    0.015976    0.034369   \n",
      "16505          0.392157    0.060379       0.073557    0.032848    0.072357   \n",
      "16506          0.764706    0.028587       0.033985    0.018610    0.038481   \n",
      "16507          0.196078    0.098784       0.092800    0.044900    0.086828   \n",
      "16508          0.666667    0.047078       0.051210    0.026766    0.055747   \n",
      "16509          0.411765    0.066229       0.063625    0.035007    0.065121   \n",
      "16510          0.117647    0.125998       0.145872    0.084167    0.150304   \n",
      "16511          0.411765    0.061753       0.064556    0.036128    0.064134   \n",
      "\n",
      "       medianIncome  \n",
      "0          0.539668  \n",
      "1          0.538027  \n",
      "2          0.466028  \n",
      "3          0.354699  \n",
      "4          0.230776  \n",
      "5          0.243921  \n",
      "6          0.217873  \n",
      "7          0.180694  \n",
      "8          0.108998  \n",
      "9          0.220087  \n",
      "10         0.186425  \n",
      "11         0.191073  \n",
      "12         0.177591  \n",
      "13         0.149908  \n",
      "14         0.097709  \n",
      "15         0.112074  \n",
      "16         0.156901  \n",
      "17         0.111743  \n",
      "18         0.102840  \n",
      "19         0.145060  \n",
      "20         0.059165  \n",
      "21         0.083695  \n",
      "22         0.084488  \n",
      "23         0.115909  \n",
      "24         0.144832  \n",
      "25         0.131302  \n",
      "26         0.135157  \n",
      "27         0.090213  \n",
      "28         0.078792  \n",
      "29         0.081902  \n",
      "...             ...  \n",
      "16482      0.137288  \n",
      "16483      0.212238  \n",
      "16484      0.217438  \n",
      "16485      0.243900  \n",
      "16486      0.171556  \n",
      "16487      0.134798  \n",
      "16488      0.225431  \n",
      "16489      0.297417  \n",
      "16490      0.290134  \n",
      "16491      0.191384  \n",
      "16492      0.167184  \n",
      "16493      0.277038  \n",
      "16494      0.201832  \n",
      "16495      0.166094  \n",
      "16496      0.214535  \n",
      "16497      0.157639  \n",
      "16498      0.164349  \n",
      "16499      0.231273  \n",
      "16500      0.142370  \n",
      "16501      0.150557  \n",
      "16502      0.135164  \n",
      "16503      0.204439  \n",
      "16504      0.130515  \n",
      "16505      0.213907  \n",
      "16506      0.194197  \n",
      "16507      0.270438  \n",
      "16508      0.197094  \n",
      "16509      0.254024  \n",
      "16510      0.202942  \n",
      "16511      0.200066  \n",
      "\n",
      "[16512 rows x 6 columns]\n",
      "0        452600.0\n",
      "1        358500.0\n",
      "2        352100.0\n",
      "3        341300.0\n",
      "4        342200.0\n",
      "5        269700.0\n",
      "6        299200.0\n",
      "7        241400.0\n",
      "8        226700.0\n",
      "9        261100.0\n",
      "10       281500.0\n",
      "11       241800.0\n",
      "12       213500.0\n",
      "13       191300.0\n",
      "14       159200.0\n",
      "15       140000.0\n",
      "16       152500.0\n",
      "17       155500.0\n",
      "18       158700.0\n",
      "19       162900.0\n",
      "20       147500.0\n",
      "21       159800.0\n",
      "22       113900.0\n",
      "23        99700.0\n",
      "24       132600.0\n",
      "25       107500.0\n",
      "26        93800.0\n",
      "27       105500.0\n",
      "28       108900.0\n",
      "29       132000.0\n",
      "           ...   \n",
      "16482    122500.0\n",
      "16483    113900.0\n",
      "16484    200000.0\n",
      "16485    174200.0\n",
      "16486    166300.0\n",
      "16487    105000.0\n",
      "16488    165200.0\n",
      "16489    161100.0\n",
      "16490    176900.0\n",
      "16491    156500.0\n",
      "16492    187500.0\n",
      "16493    152200.0\n",
      "16494    158900.0\n",
      "16495    113400.0\n",
      "16496    141300.0\n",
      "16497    110900.0\n",
      "16498    141900.0\n",
      "16499    157600.0\n",
      "16500    200000.0\n",
      "16501    169400.0\n",
      "16502     97100.0\n",
      "16503     90900.0\n",
      "16504    102200.0\n",
      "16505    134600.0\n",
      "16506    125900.0\n",
      "16507    182700.0\n",
      "16508    149000.0\n",
      "16509    192100.0\n",
      "16510    139000.0\n",
      "16511    182400.0\n",
      "Name: medianHouseValue, Length: 16512, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Columns\n",
    "\n",
    "** Create the necessary tf.feature_column objects for the estimator. They should all be trated as continuous numeric_columns. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "housingMedianAge = tf.feature_column.numeric_column('housingMedianAge')\n",
    "totalRooms = tf.feature_column.numeric_column('totalRooms')\n",
    "totalBedrooms = tf.feature_column.numeric_column('totalBedrooms')\n",
    "population = tf.feature_column.numeric_column('population')\n",
    "households = tf.feature_column.numeric_column('households')\n",
    "medianIncome = tf.feature_column.numeric_column('medianIncome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols =  [housingMedianAge,totalRooms,totalBedrooms,population,households,medianIncome]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the input function for the estimator object. (play around with batch_size and num_epochs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_function = tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train,batch_size=10,num_epochs=1000,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the estimator model. Use a DNNRegressor. Play around with the hidden units! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpzfqg3sj1\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpzfqg3sj1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe09ce80518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.DNNRegressor(hidden_units= [6,6,6],feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ** Train the model for ~1,000 steps. (Later come back to this and train it for more and check for improvement) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpzfqg3sj1/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into /tmp/tmpzfqg3sj1/model.ckpt.\n",
      "INFO:tensorflow:loss = 69988600000.0, step = 30001\n",
      "INFO:tensorflow:global_step/sec: 396.23\n",
      "INFO:tensorflow:loss = 42952020000.0, step = 30101 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 497.599\n",
      "INFO:tensorflow:loss = 27055337000.0, step = 30201 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.207\n",
      "INFO:tensorflow:loss = 173378730000.0, step = 30301 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.729\n",
      "INFO:tensorflow:loss = 84089094000.0, step = 30401 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.254\n",
      "INFO:tensorflow:loss = 94077590000.0, step = 30501 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.488\n",
      "INFO:tensorflow:loss = 52749623000.0, step = 30601 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.111\n",
      "INFO:tensorflow:loss = 123557540000.0, step = 30701 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.007\n",
      "INFO:tensorflow:loss = 84507160000.0, step = 30801 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.114\n",
      "INFO:tensorflow:loss = 88214240000.0, step = 30901 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.753\n",
      "INFO:tensorflow:loss = 155146730000.0, step = 31001 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.361\n",
      "INFO:tensorflow:loss = 61746300000.0, step = 31101 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.036\n",
      "INFO:tensorflow:loss = 61096670000.0, step = 31201 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.317\n",
      "INFO:tensorflow:loss = 75267645000.0, step = 31301 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.492\n",
      "INFO:tensorflow:loss = 62752408000.0, step = 31401 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.423\n",
      "INFO:tensorflow:loss = 137311830000.0, step = 31501 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.784\n",
      "INFO:tensorflow:loss = 265380000000.0, step = 31601 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.461\n",
      "INFO:tensorflow:loss = 100163174000.0, step = 31701 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.02\n",
      "INFO:tensorflow:loss = 16899756000.0, step = 31801 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.065\n",
      "INFO:tensorflow:loss = 83018540000.0, step = 31901 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.007\n",
      "INFO:tensorflow:loss = 152093410000.0, step = 32001 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.44\n",
      "INFO:tensorflow:loss = 44760790000.0, step = 32101 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.388\n",
      "INFO:tensorflow:loss = 9233857000.0, step = 32201 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.51\n",
      "INFO:tensorflow:loss = 50318852000.0, step = 32301 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.73\n",
      "INFO:tensorflow:loss = 47385117000.0, step = 32401 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.899\n",
      "INFO:tensorflow:loss = 85689836000.0, step = 32501 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.202\n",
      "INFO:tensorflow:loss = 124162990000.0, step = 32601 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.162\n",
      "INFO:tensorflow:loss = 139595920000.0, step = 32701 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.925\n",
      "INFO:tensorflow:loss = 48360178000.0, step = 32801 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.217\n",
      "INFO:tensorflow:loss = 110453490000.0, step = 32901 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.216\n",
      "INFO:tensorflow:loss = 77954100000.0, step = 33001 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.358\n",
      "INFO:tensorflow:loss = 30204060000.0, step = 33101 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.342\n",
      "INFO:tensorflow:loss = 97238650000.0, step = 33201 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.311\n",
      "INFO:tensorflow:loss = 125084830000.0, step = 33301 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.498\n",
      "INFO:tensorflow:loss = 57096385000.0, step = 33401 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.461\n",
      "INFO:tensorflow:loss = 24213885000.0, step = 33501 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.15\n",
      "INFO:tensorflow:loss = 226128920000.0, step = 33601 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.705\n",
      "INFO:tensorflow:loss = 81083834000.0, step = 33701 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.809\n",
      "INFO:tensorflow:loss = 145569810000.0, step = 33801 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.264\n",
      "INFO:tensorflow:loss = 68128220000.0, step = 33901 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.622\n",
      "INFO:tensorflow:loss = 110886080000.0, step = 34001 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.833\n",
      "INFO:tensorflow:loss = 170719180000.0, step = 34101 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.132\n",
      "INFO:tensorflow:loss = 104770300000.0, step = 34201 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.867\n",
      "INFO:tensorflow:loss = 215253760000.0, step = 34301 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.814\n",
      "INFO:tensorflow:loss = 46728053000.0, step = 34401 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.643\n",
      "INFO:tensorflow:loss = 73662530000.0, step = 34501 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.042\n",
      "INFO:tensorflow:loss = 120868440000.0, step = 34601 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.834\n",
      "INFO:tensorflow:loss = 76493690000.0, step = 34701 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.926\n",
      "INFO:tensorflow:loss = 64892342000.0, step = 34801 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.554\n",
      "INFO:tensorflow:loss = 96512620000.0, step = 34901 (0.236 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 35000 into /tmp/tmpzfqg3sj1/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 80660880000.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x7fe09ce80d68>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn= input_function,steps = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a prediction input function and then use the .predict method off your estimator model to create a list or predictions on your test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_fn = tf.estimator.inputs.pandas_input_fn(x=X_test,num_epochs=1,batch_size=32,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gen  = estimator.predict(input_fn=prediction_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpzfqg3sj1/model.ckpt-35000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = list(pred_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Calculate the RMSE. You should be able to get around 100,000 RMSE (remember that this is in the same units as the label.) Do this manually or use [sklearn.metrics](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = []\n",
    "for pred in predictions:\n",
    "    final_pred.append(pred['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99628.637407549"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(final_pred,y_test)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
